# -*- coding: utf-8 -*-
"""projeto_final_gpu_cifar10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z8lCoWcRnWv8KNUwwBKUxPQwYQGUxf9y

# Projeto Final — Classificação de Imagens em GPU (CIFAR‑10)
Este notebook demonstra o desenvolvimento completo de um classificador de imagens using **CNN em GPU** aplicando os conceitos de computação paralela abordados no curso.

**Tarefa:** Classificar imagens do conjunto **CIFAR‑10** em 10 categorias.
**Biblioteca:** TensorFlow 2.x (CUDA).  
**Métricas de avaliação:** acurácia top‑1 em validação e tempo de treinamento.
**Estrutura:**
1. Instalação e verificação de GPU  
2. Carregamento e pré‑processamento dos dados  
3. Construção da CNN (modelo baseline + opção ResNet‑like)  
4. Treinamento e medição de tempo  
5. Avaliação em teste e análise de desempenho  
6. Comentários e direções futuras
"""

!pip install -q tensorflow==2.15.5 numpy==1.26.4

import tensorflow as tf, numpy as np, matplotlib.pyplot as plt, time

(trainX, trainy), (testX, testy) = tf.keras.datasets.cifar10.load_data()
trainX, testX = trainX.astype('float32')/255.0, testX.astype('float32')/255.0
print('Dados:', trainX.shape, testX.shape)

"""## 1. Carregamento do CIFAR‑10"""

(trainX, trainy), (testX, testy) = tf.keras.datasets.cifar10.load_data()
trainX, testX = trainX.astype('float32')/255.0, testX.astype('float32')/255.0
class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']
print('Dados:', trainX.shape, testX.shape)

plt.figure(figsize=(8,2))
for i in range(10):
    plt.subplot(1,10,i+1)
    plt.imshow(trainX[i]); plt.axis('off'); plt.title(class_names[int(trainy[i])], fontsize=8)
plt.show()

"""## 2. Definição da CNN (modelo simples)"""

def build_cnn():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(32,32,3)),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same'),
        tf.keras.layers.MaxPooling2D((2,2)),
        tf.keras.layers.Dropout(0.25),

        tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),
        tf.keras.layers.MaxPooling2D((2,2)),
        tf.keras.layers.Dropout(0.25),

        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(10, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model
model = build_cnn()
model.summary()

"""## 3. Treinamento em GPU e medição de tempo"""

import time

epochs = 20
batch = 128
t0 = time.perf_counter()
history = model.fit(trainX, trainy, epochs=epochs, batch_size=batch, validation_split=0.1, verbose=2)
train_time = time.perf_counter() - t0
print(f'Tempo total de treinamento: {train_time/60:.2f} min')

"""## 4. Avaliação e matriz de confusão"""

test_loss, test_acc = model.evaluate(testX, testy, verbose=0)
print(f'Acurácia de teste: {test_acc:.4f}')

# Matriz de confusão
from sklearn.metrics import confusion_matrix
preds = np.argmax(model.predict(testX, verbose=0), axis=1)
cm = confusion_matrix(testy.flatten(), preds)
import seaborn as sns
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predito'); plt.ylabel('Real'); plt.title('Confusion Matrix'); plt.show()

"""## 5. Curvas de aprendizagem"""

plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='train')
plt.plot(history.history['val_accuracy'], label='val')
plt.title('Acurácia')
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='val')
plt.title('Loss')
plt.legend()
plt.show()

"""## 6. Discussão
- O treinamento explora paralelismo de dados e operações convolucionais em GPU via CUDA, reduzindo tempo em várias ordens de magnitude comparado à CPU.
- A acurácia de ~80‑85 % é típica para CNN simples em CIFAR‑10; melhores arquiteturas (e.g., ResNet‑20) podem ultrapassar 90 % mantendo execução em GPU.
- O projeto pode ser estendido com data augmentation, scheduler de taxa de aprendizado ou mixed‑precision FP16 para acelerar ainda mais.
Este notebook serve como fundação sólida para aplicações de classificação de imagens em paralelo na GPU.
"""